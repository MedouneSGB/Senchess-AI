# Senchess AI - ModÃ¨le de DÃ©tection de PiÃ¨ces d'Ã‰checs

Ce projet contient le code et les ressources pour entraÃ®ner un modÃ¨le de vision par ordinateur capable de dÃ©tecter la position des piÃ¨ces sur un Ã©chiquier Ã  partir d'une image. Ce modÃ¨le est conÃ§u pour Ãªtre intÃ©grÃ© Ã  **Senchess.com**, une plateforme d'Ã©checs en ligne avec des fonctionnalitÃ©s d'IA avancÃ©es.

## ğŸ¯ ModÃ¨les Disponibles

Nous avons entraÃ®nÃ© **2 modÃ¨les de production** spÃ©cialisÃ©s :

| ModÃ¨le | mAP50 | SpÃ©cialitÃ© | Meilleur pour |
|--------|-------|------------|---------------|
| **ğŸ¥‡ Senchess Haki v1.0** | 99.5% | Diagrammes 2D gÃ©nÃ©rÃ©s | Images Chess Decoder, graphiques stylisÃ©s |
| **ğŸ¥ˆ Senchess Gear v1.0** | 98.5% | Photos physiques 3D | Photos smartphone d'Ã©chiquiers rÃ©els |

## ï¿½ API REST DÃ©ployable

**Nouveau !** Une API Flask complÃ¨te pour dÃ©ployer vos modÃ¨les sur Vercel et les utiliser dans vos applications web.

### DÃ©marrage rapide

```bash
# 1. Uploader vos modÃ¨les sur Hugging Face
pip install huggingface_hub
python upload_models_to_huggingface.py

# 2. DÃ©ployer sur Vercel
npm i -g vercel
vercel --prod
```

### Utilisation

```typescript
// Dans votre application web
import { analyzeChessBoardImage } from './chessImageRecognition';

const result = await analyzeChessBoardImage(imageUrl);
console.log('FEN:', result.fen);  // Position en notation FEN
console.log('PiÃ¨ces:', result.detectedPieces);  // Nombre de piÃ¨ces dÃ©tectÃ©es
```

**ğŸ“š Documentation complÃ¨te :**
- [`QUICK_START.md`](QUICK_START.md) - Guide de dÃ©ploiement express (5 Ã©tapes)
- [`HUGGINGFACE_GUIDE.md`](HUGGINGFACE_GUIDE.md) - Upload des modÃ¨les sur Hugging Face
- [`DEPLOYMENT.md`](DEPLOYMENT.md) - Guide de dÃ©ploiement complet
- [`COMMANDS.md`](COMMANDS.md) - Toutes les commandes utiles
- [`api/README.md`](api/README.md) - Documentation de l'API

## ï¿½ğŸ“‹ Table des MatiÃ¨res

- [ModÃ¨les Disponibles](#-modÃ¨les-disponibles)
- [API REST DÃ©ployable](#-api-rest-dÃ©ployable)
- [Structure du Projet](#structure-du-projet)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [Installation](#installation)
- [Utilisation Rapide](#utilisation-rapide)
- [Utilisation AvancÃ©e](#utilisation-avancÃ©e)
  - [1. Gestionnaire de ModÃ¨les](#1-gestionnaire-de-modÃ¨les)
  - [2. EntraÃ®nement](#2-entraÃ®nement)
  - [3. PrÃ©diction](#3-prÃ©diction)
  - [4. Ã‰valuation](#4-Ã©valuation)
- [Dataset](#dataset)
- [RÃ©sultats](#rÃ©sultats)
- [Exemples](#exemples)

## ğŸ“ Structure du Projet

```
Senchess AI/
â”œâ”€â”€ data/                           # DonnÃ©es d'entraÃ®nement (1693 images total)
â”‚   â”œâ”€â”€ processed/                  # Dataset Gear (693 images - photos 3D)
â”‚   â”‚   â”œâ”€â”€ train/                  # Ensemble d'entraÃ®nement (485 images)
â”‚   â”‚   â”œâ”€â”€ valid/                  # Ensemble de validation (58 images)
â”‚   â”‚   â””â”€â”€ test/                   # Ensemble de test (150 images)
â”‚   â”œâ”€â”€ chess_decoder_1000/         # Dataset Haki (1000 images - diagrammes 2D)
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/              # 700 images
â”‚   â”‚   â”‚   â”œâ”€â”€ val/                # 200 images
â”‚   â”‚   â”‚   â””â”€â”€ test/               # 100 images
â”‚   â”‚   â””â”€â”€ labels/
â”‚   â””â”€â”€ chess_dataset.yaml          # Configuration dataset Gear
â”œâ”€â”€ src/                            # Code source
â”‚   â”œâ”€â”€ train.py                    # Script d'entraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ predict.py                  # Script d'infÃ©rence simple
â”‚   â”œâ”€â”€ model_manager.py            # ğŸ†• Gestionnaire de modÃ¨les professionnel
â”‚   â”œâ”€â”€ evaluate.py                 # ğŸ†• Ã‰valuation et comparaison
â”‚   â”œâ”€â”€ adapt_roboflow_dataset.py   # DÃ©tection automatique des couleurs
â”‚   â”œâ”€â”€ merge_datasets.py           # Fusion de datasets YOLO
â”‚   â””â”€â”€ prepare_data.py             # PrÃ©paration des donnÃ©es
â”œâ”€â”€ models/                         # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ senchess_haki_v1.0/         # ğŸ¥‡ Meilleur modÃ¨le (99.5% mAP50)
â”‚   â”‚   â””â”€â”€ weights/
â”‚   â”‚       â””â”€â”€ best.pt             # 6.0MB - Diagrammes 2D
â”‚   â”œâ”€â”€ senchess_gear_v1.0/         # ğŸ¥ˆ Second modÃ¨le (98.5% mAP50)
â”‚   â”‚   â””â”€â”€ weights/
â”‚   â”‚       â””â”€â”€ best.pt             # 6.0MB - Photos physiques
â”‚   â””â”€â”€ MODEL_CONFIG.yaml           # Configuration complÃ¨te des modÃ¨les
â”œâ”€â”€ predictions/                    # RÃ©sultats des prÃ©dictions
â”œâ”€â”€ imgTest/                        # Images de test
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ .gitignore                      # Fichiers Ã  ignorer
â””â”€â”€ README.md                       # Ce fichier
```

## ğŸ› ï¸ Technologies UtilisÃ©es

- **YOLOv8** (Ultralytics) - Architecture de dÃ©tection d'objets state-of-the-art
- **PyTorch** - Framework de deep learning
- **OpenCV** - Traitement d'images
- **Python 3.9+** - Langage de programmation

## ğŸ’» Installation

### PrÃ©requis

- Python 3.9 Ã  3.11 (Python 3.13 n'est pas encore compatible avec PyTorch)
- pip

### Ã‰tapes d'installation

1. **Clonez le projet** (si applicable) :
   ```bash
   git clone <url-du-repo>
   cd "Senchess AI"
   ```

2. **CrÃ©ez un environnement virtuel** :
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # Sur macOS/Linux
   # .venv\Scripts\activate   # Sur Windows
   ```

3. **Installez les dÃ©pendances** :
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

## ğŸš€ Utilisation Rapide

### Utiliser les ModÃ¨les PrÃ©-EntraÃ®nÃ©s

```python
from src.model_manager import SenchessModelManager

# Initialiser le gestionnaire
manager = SenchessModelManager()

# Lister les modÃ¨les disponibles
manager.list_models()

# Charger et utiliser Haki (meilleur pour diagrammes 2D)
haki = manager.load_model('haki')
results = manager.predict('haki', 'votre_image.png')

# Charger et utiliser Gear (meilleur pour photos physiques)
gear = manager.load_model('gear')
results = manager.predict('gear', 'photo_echiquier.jpg')

# Comparer les 2 modÃ¨les sur la mÃªme image
comparison = manager.compare_models('test_image.jpg')
```

### En Ligne de Commande

```bash
# Lister les modÃ¨les disponibles
python src/model_manager.py --list

# PrÃ©diction avec Haki
python src/model_manager.py --model haki --image imgTest/capture3.png

# PrÃ©diction avec Gear
python src/model_manager.py --model gear --image imgTest/capture2.jpg

# Comparer les 2 modÃ¨les
python src/model_manager.py --compare --image imgTest/capture2.jpg
```

## ğŸ”§ Utilisation AvancÃ©e

### 1. Gestionnaire de ModÃ¨les

Le `SenchessModelManager` offre une API complÃ¨te :

```python
from src.model_manager import SenchessModelManager

manager = SenchessModelManager()

# Obtenir les informations d'un modÃ¨le
info = manager.get_model_info('haki')
print(f"mAP50: {info['metrics']['mAP50']}%")

# Recommandation automatique selon le cas d'usage
best_model = manager.recommend_model('user_photos')  # Retourne 'gear'
best_model = manager.recommend_model('generated_images')  # Retourne 'haki'
```

### 2. EntraÃ®nement

EntraÃ®nez un nouveau modÃ¨le YOLOv8 sur votre dataset :

```bash
# EntraÃ®nement de base (10 Ã©poques)
python src/train.py

# EntraÃ®nement standard (50 Ã©poques)
python src/train.py --epochs 50 --project models --name mon_nouveau_modele

# EntraÃ®nement approfondi (100 Ã©poques)
python src/train.py --epochs 100 --batch-size 8

# Fine-tuning d'un modÃ¨le existant
python src/train.py --model models/senchess_gear_v1.0/weights/best.pt --epochs 20
```

**ParamÃ¨tres disponibles** :
- `--epochs` : Nombre d'Ã©poques (par dÃ©faut : 10)
- `--batch-size` : Taille du batch (par dÃ©faut : 8)
- `--img-size` : Taille des images (par dÃ©faut : 640)
- `--model` : ModÃ¨le de base (`yolov8n.pt` ou chemin vers .pt existant)
- `--project` : Dossier de sortie (par dÃ©faut : `models`)
- `--name` : Nom du modÃ¨le (par dÃ©faut : auto-gÃ©nÃ©rÃ©)

Le modÃ¨le entraÃ®nÃ© sera sauvegardÃ© dans `models/<name>/weights/best.pt`.

### 3. PrÃ©diction

Utilisez les modÃ¨les entraÃ®nÃ©s pour dÃ©tecter les piÃ¨ces :

```bash
# PrÃ©diction simple avec le modÃ¨le par dÃ©faut
python src/predict.py --image-path imgTest/capture2.jpg

# Avec seuil de confiance personnalisÃ©
python src/predict.py --image-path imgTest/capture2.jpg --conf 0.5

# Sans sauvegarder l'image annotÃ©e
python src/predict.py --image-path imgTest/capture2.jpg --no-save

# Utiliser un modÃ¨le spÃ©cifique
python src/predict.py --image-path imgTest/capture3.png --model models/senchess_haki_v1.0/weights/best.pt
```

Les rÃ©sultats incluent :
- Une image annotÃ©e avec les boÃ®tes englobantes (dans `predictions/`)
- Un fichier JSON avec les coordonnÃ©es et classes de chaque piÃ¨ce dÃ©tectÃ©e

### 4. Ã‰valuation

Ã‰valuez et comparez les performances des modÃ¨les :

```bash
# Ã‰valuer un modÃ¨le sur l'ensemble de test
python src/evaluate.py --model haki

# Comparer les 2 modÃ¨les
python src/evaluate.py --compare

# Ã‰valuation dÃ©taillÃ©e avec mÃ©triques par classe
python src/evaluate.py --model haki --detailed
```

## ğŸ“Š Dataset

Le projet utilise **2 datasets complÃ©mentaires** :

### Dataset 1 : Senchess Gear (693 images)
- **Type** : Photos d'Ã©chiquiers physiques 3D
- **Source** : Images personnelles
- **RÃ©partition** : 485 train / 58 valid / 150 test
- **13 classes** avec distinction noir/blanc :
  - PiÃ¨ces noires : black-bishop, black-king, black-knight, black-pawn, black-queen, black-rook
  - PiÃ¨ces blanches : white-bishop, white-king, white-knight, white-pawn, white-queen, white-rook
  - PiÃ¨ce gÃ©nÃ©rique : bishop (fou)

### Dataset 2 : Senchess Haki (1000 images)
- **Type** : Diagrammes d'Ã©checs 2D gÃ©nÃ©rÃ©s par Chess Decoder
- **Source** : Chess Decoder dataset
- **RÃ©partition** : 700 train / 200 val / 100 test
- **MÃªmes 13 classes** avec distinction noir/blanc
- **Styles variÃ©s** : ocean, marble, wood, classic, sunset, forest, neon, gold-silver

Les annotations sont au format YOLO (fichiers `.txt` avec coordonnÃ©es normalisÃ©es).

## ğŸ“ˆ RÃ©sultats

### Performances des ModÃ¨les

| ModÃ¨le | Dataset | Images | mAP50 | mAP50-95 | Precision | Recall | DurÃ©e |
|--------|---------|--------|-------|----------|-----------|--------|-------|
| **Senchess Haki v1.0** | Chess Decoder (1000) | 1000 | **99.5%** | 85.3% | 98.2% | 97.8% | 2.24h |
| **Senchess Gear v1.0** | Photos (693) | 693 | **98.5%** | 71.2% | 95.8% | 94.3% | 11.7h |

### SpÃ©cialisations

- **Senchess Haki v1.0** ğŸ¥‡
  - âœ… Excellent sur diagrammes 2D gÃ©nÃ©rÃ©s
  - âœ… Reconnaissance de styles variÃ©s (ocean, marble, wood, etc.)
  - âœ… PrÃ©cision quasi-parfaite sur images Chess Decoder
  - âš ï¸ Moins performant sur photos physiques rÃ©elles

- **Senchess Gear v1.0** ğŸ¥ˆ
  - âœ… Excellent sur photos d'Ã©chiquiers physiques
  - âœ… Robuste aux variations d'Ã©clairage
  - âœ… Performances optimales sur images smartphone
  - âš ï¸ Moins performant sur diagrammes gÃ©nÃ©rÃ©s

### Recommandations d'Usage

```python
# Pour photos d'Ã©chiquiers rÃ©els (smartphone, appareil photo)
manager.predict('gear', 'photo_echiquier.jpg')

# Pour diagrammes gÃ©nÃ©rÃ©s (Chess Decoder, captures d'Ã©cran)
manager.predict('haki', 'diagramme.png')

# Pour usage hybride, comparez les 2
manager.compare_models('image_inconnue.jpg')
```

## ğŸ–¼ï¸ Exemples

### Exemple 1 : Photo d'Ã©chiquier physique (Gear)

```python
from src.model_manager import SenchessModelManager

manager = SenchessModelManager()
results = manager.predict('gear', 'imgTest/capture2.jpg')
```

**RÃ©sultat** : 32 piÃ¨ces dÃ©tectÃ©es avec confiance moyenne de 94.3%

### Exemple 2 : Diagramme Chess Decoder (Haki)

```python
results = manager.predict('haki', 'imgTest/capture3.png')
```

**RÃ©sultat** : 32 piÃ¨ces dÃ©tectÃ©es avec confiance moyenne de 98.7%

### Exemple 3 : Comparaison des modÃ¨les

```python
comparison = manager.compare_models('imgTest/capture2.jpg')
print(f"Gear: {comparison['gear']['detections']} dÃ©tections")
print(f"Haki: {comparison['haki']['detections']} dÃ©tections")
```

## ğŸ¯ Prochaines Ã‰tapes

- [ ] CrÃ©er Senchess Ultimate (fusion 1693 images pour modÃ¨le universel)
- [ ] IntÃ©gration avec l'API REST de Senchess.com
- [ ] Support de la dÃ©tection en temps rÃ©el (vidÃ©o)
- [ ] Tests unitaires et CI/CD
- [ ] Export du modÃ¨le pour dÃ©ploiement mobile (ONNX, TFLite)
- [ ] Dashboard de monitoring en production

## ğŸ“ Notes Techniques

### CPU vs GPU
- **EntraÃ®nement sur CPU** : Possible mais lent (1-2h par 10 Ã©poques sur 1000 images)
- **GPU recommandÃ©** : NVIDIA avec CUDA pour accÃ©lÃ©ration 10-20x
- **Alternative** : Google Colab avec GPU gratuit

### Taille des ModÃ¨les
- **YOLOv8n** (nano) : 6MB, 3M paramÃ¨tres, le plus rapide
- **YOLOv8s** (small) : 22MB, 11M paramÃ¨tres, meilleur compromis
- **YOLOv8m** (medium) : 52MB, 26M paramÃ¨tres, haute prÃ©cision

### AmÃ©lioration des Performances
- **Plus de donnÃ©es** : VariÃ©tÃ© d'Ã©chiquiers, angles, Ã©clairages
- **Data augmentation** : Rotation, flip, changement luminositÃ©
- **Fine-tuning** : Partir d'un modÃ¨le prÃ©-entraÃ®nÃ©
- **Ensemble** : Combiner plusieurs modÃ¨les

## ğŸ¤ Contribution

Pour contribuer au projet :
1. Fork le repository
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Commitez vos changements (`git commit -m 'Ajout fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

## ï¿½ Documentation ComplÃ¨te

Pour plus de dÃ©tails sur le projet :
- **[docs/SUMMARY.md](docs/SUMMARY.md)** - RÃ©sumÃ© exÃ©cutif du projet
- **[docs/IMPROVEMENTS.md](docs/IMPROVEMENTS.md)** - Rapport des amÃ©liorations Court Terme
- **[docs/CHANGELOG.md](docs/CHANGELOG.md)** - Historique des versions
- **[docs/PROJECT_STATUS.txt](docs/PROJECT_STATUS.txt)** - Statut visuel du projet
- **[models/MODEL_CONFIG.yaml](models/MODEL_CONFIG.yaml)** - Configuration dÃ©taillÃ©e des modÃ¨les

## ï¿½ğŸ“œ License

Ce projet est sous licence [MIT](LICENSE).

## ğŸ“§ Contact

Pour toute question concernant ce projet, veuillez contacter l'Ã©quipe Senchess.com.

---

**ModÃ¨les Actuels** : Senchess Haki v1.0 (99.5%) | Senchess Gear v1.0 (98.5%)

**Happy Chess Learning!** â™Ÿï¸ğŸ¤–ğŸ¯
