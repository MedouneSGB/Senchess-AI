# ğŸ¯ Guide de Fine-Tuning Senchess AI

Ce guide explique comment fine-tuner les modÃ¨les pour amÃ©liorer leurs performances.

---

## ğŸ“‹ Options Disponibles

### Option 1 : Gear v1.1 (Quick Win) âš¡
**DurÃ©e :** 2-3 heures  
**Objectif :** 98.5% â†’ 99%+ mAP50

```bash
./run_finetune_gear.sh
```

**Ce qui se passe :**
- Part de Gear v1.0 (98.5% mAP50)
- 30 epochs supplÃ©mentaires
- Learning rate rÃ©duit (0.0001)
- Dataset : 693 images (photos physiques)

---

### Option 2 : Gear-Haki Ultimate ğŸ†
**DurÃ©e :** 4-6 heures  
**Objectif :** ModÃ¨le universel 2D + 3D

```bash
./run_finetune.sh
```

**Ce qui se passe :**
1. **Fusion des datasets** (automatique)
   - Gear : 693 images (photos 3D)
   - Haki : 1000 images (diagrammes 2D)
   - Total : 1693 images

2. **Fine-tuning depuis Haki v1.0**
   - Meilleur modÃ¨le de base (99.5% mAP50)
   - 50 epochs
   - Learning rate : 0.001

---

## ğŸ”§ Fine-Tuning Manuel

### Script Python
```bash
source .venv/bin/activate

python src/finetune.py \
    --gear-data data/processed \
    --haki-data data/chess_decoder_1000 \
    --output-data data/gear_haki_merged \
    --base-model models/senchess_haki_v1.0/weights/best.pt \
    --epochs 50 \
    --lr0 0.001 \
    --name senchess_gear_haki_finetune
```

### Options disponibles
```
--gear-data      : Chemin dataset Gear (dÃ©faut: data/processed)
--haki-data      : Chemin dataset Haki (dÃ©faut: data/chess_decoder_1000)
--output-data    : Chemin dataset fusionnÃ© (dÃ©faut: data/gear_haki_merged)
--base-model     : ModÃ¨le de base (dÃ©faut: haki v1.0)
--epochs         : Nombre d'epochs (dÃ©faut: 50)
--lr0            : Learning rate (dÃ©faut: 0.001)
--name           : Nom du modÃ¨le (dÃ©faut: senchess_gear_haki_finetune)
--skip-merge     : Skip fusion dataset (si dÃ©jÃ  fait)
```

---

## ğŸ“Š RÃ©sultats Attendus

### Gear v1.1
- **mAP50 :** 99%+ (vs 98.5%)
- **SpÃ©cialisation :** Photos physiques 3D
- **Usage :** Production pour photos smartphone

### Gear-Haki Ultimate
- **mAP50 :** 99%+ (objectif)
- **SpÃ©cialisation :** Universel (2D + 3D)
- **Usage :** Production pour tous types d'images

---

## ğŸ§ª Ã‰valuation

AprÃ¨s le fine-tuning, Ã©valuez le nouveau modÃ¨le :

```bash
# Ã‰valuation simple
python src/evaluate.py --model models/senchess_gear_v1.1/weights/best.pt

# Comparaison avec modÃ¨les existants
python src/evaluate.py --compare

# MÃ©triques dÃ©taillÃ©es par classe
python src/evaluate.py --model models/senchess_gear_v1.1/weights/best.pt --detailed

# Benchmark sur image
python src/evaluate.py --benchmark imgTest/capture2.jpg
```

---

## ğŸ“ˆ Monitoring

Pendant l'entraÃ®nement, suivez :

### Terminal
- Loss progression
- mAP50 / mAP50-95
- Precision / Recall
- Temps par epoch

### Fichiers gÃ©nÃ©rÃ©s
```
models/[nom_modele]/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt           # Meilleur modÃ¨le (mAP50)
â”‚   â””â”€â”€ last.pt           # Dernier epoch
â”œâ”€â”€ results.csv           # MÃ©triques par epoch
â”œâ”€â”€ results.png           # Courbes d'apprentissage
â”œâ”€â”€ confusion_matrix.png  # Matrice de confusion
â””â”€â”€ args.yaml            # Configuration
```

---

## ğŸ’¡ Conseils

### Pour amÃ©liorer mAP50
- âœ… Augmenter epochs (30-100)
- âœ… RÃ©duire learning rate (0.0001-0.001)
- âœ… Activer data augmentation
- âœ… Partir du meilleur modÃ¨le

### Pour Ã©viter l'overfitting
- âš ï¸ Early stopping (patience=50)
- âš ï¸ Validation rÃ©guliÃ¨re
- âš ï¸ Dropout si nÃ©cessaire
- âš ï¸ Surveiller val_loss

### Pour accÃ©lÃ©rer
- ğŸš€ RÃ©duire batch size si RAM limitÃ©e
- ğŸš€ Utiliser GPU si disponible (--device cuda)
- ğŸš€ RÃ©duire image size (--imgsz 416)

---

## ğŸ› Troubleshooting

### ProblÃ¨me : CUDA Out of Memory
```bash
# Solution : RÃ©duire batch size
python src/finetune.py --batch 4  # au lieu de 8
```

### ProblÃ¨me : Val Loss augmente
```bash
# Solution : RÃ©duire learning rate
python src/finetune.py --lr0 0.0001
```

### ProblÃ¨me : Dataset merge Ã©choue
```bash
# Solution : Skip merge si dÃ©jÃ  fait
python src/finetune.py --skip-merge
```

---

## ğŸ“Š Comparaison des StratÃ©gies

| StratÃ©gie | DurÃ©e | ComplexitÃ© | mAP50 attendu | Usage |
|-----------|-------|------------|---------------|-------|
| Gear v1.1 | 2-3h | â­ Facile | 99%+ | Photos 3D uniquement |
| Ultimate | 4-6h | â­â­ Moyenne | 99%+ | Universel 2D + 3D |
| Custom | Variable | â­â­â­ AvancÃ© | Variable | Cas spÃ©cifique |

---

## ğŸš€ Prochaines Ã‰tapes

AprÃ¨s le fine-tuning :

1. **Ã‰valuation complÃ¨te**
   ```bash
   python src/evaluate.py --model models/[nouveau_modele]/weights/best.pt --detailed
   ```

2. **Benchmark comparatif**
   ```bash
   python src/evaluate.py --compare
   ```

3. **Tests en production**
   ```bash
   python src/predict.py --model models/[nouveau_modele]/weights/best.pt --source imgTest/
   ```

4. **Mise Ã  jour MODEL_CONFIG.yaml**
   - Ajouter les nouvelles mÃ©triques
   - Documenter les spÃ©cialisations
   - Versionner le modÃ¨le

5. **Commit et push**
   ```bash
   git add models/[nouveau_modele]
   git commit -m "ğŸ¯ Ajout [nouveau_modele] via fine-tuning"
   git push origin main
   ```

---

## ğŸ“ Notes

- Le fine-tuning conserve les connaissances du modÃ¨le de base
- Learning rate plus faible = apprentissage plus stable
- Plus d'epochs = meilleure performance (jusqu'Ã  un certain point)
- Toujours valider sur donnÃ©es de test non vues

---

**ğŸ¯ Bon fine-tuning !**
