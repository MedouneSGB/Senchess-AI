"""
API Flask pour la d√©tection de pi√®ces d'√©checs avec YOLO
D√©ployable sur Vercel
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import io
import base64
import numpy as np
from PIL import Image
import cv2
from ultralytics import YOLO
from pathlib import Path
import tempfile

app = Flask(__name__)
CORS(app)  # Permettre les requ√™tes cross-origin

# Configuration des mod√®les
HUGGINGFACE_REPO = os.environ.get('HUGGINGFACE_REPO_ID', 'MedouneSGB/senchess-models')
MODEL_TYPE = os.environ.get('MODEL_TYPE', 'gear')  # 'gear', 'haki', ou 'ensemble'
USE_HUGGINGFACE = os.environ.get('USE_HUGGINGFACE', 'true').lower() == 'true'

# Variables globales pour les mod√®les
model_gear = None
model_haki = None

def download_model_from_huggingface(model_name):
    """T√©l√©charge un mod√®le depuis Hugging Face Hub"""
    try:
        from huggingface_hub import hf_hub_download
        
        print(f"üì• T√©l√©chargement de {model_name} depuis Hugging Face...")
        
        model_path = hf_hub_download(
            repo_id=HUGGINGFACE_REPO,
            filename=model_name,
            cache_dir="/tmp/models"
        )
        
        print(f"‚úÖ Mod√®le t√©l√©charg√©: {model_path}")
        return model_path
        
    except ImportError:
        print("‚ùå huggingface_hub non install√©")
        return None
    except Exception as e:
        print(f"‚ùå Erreur t√©l√©chargement: {e}")
        return None

def load_model():
    """Charge le(s) mod√®le(s) YOLO"""
    global model_gear, model_haki
    
    try:
        if USE_HUGGINGFACE:
            # Charger depuis Hugging Face
            print(f"üîÑ Chargement des mod√®les depuis Hugging Face ({HUGGINGFACE_REPO})...")
            
            if MODEL_TYPE in ['gear', 'ensemble']:
                gear_path = download_model_from_huggingface('gear_v1.1.pt')
                if gear_path:
                    model_gear = YOLO(gear_path)
                    print("‚úÖ Mod√®le Gear charg√©")
            
            if MODEL_TYPE in ['haki', 'ensemble']:
                haki_path = download_model_from_huggingface('haki_v1.0.pt')
                if haki_path:
                    model_haki = YOLO(haki_path)
                    print("‚úÖ Mod√®le Haki charg√©")
        
        else:
            # Charger depuis fichiers locaux (pour d√©veloppement local)
            print("üîÑ Chargement des mod√®les depuis fichiers locaux...")
            
            gear_local = 'models/senchess_gear_v1.1/weights/best.pt'
            haki_local = 'models/senchess_haki_v1.0/weights/best.pt'
            
            if MODEL_TYPE in ['gear', 'ensemble'] and os.path.exists(gear_local):
                model_gear = YOLO(gear_local)
                print(f"‚úÖ Mod√®le Gear charg√© depuis: {gear_local}")
            
            if MODEL_TYPE in ['haki', 'ensemble'] and os.path.exists(haki_local):
                model_haki = YOLO(haki_local)
                print(f"‚úÖ Mod√®le Haki charg√© depuis: {haki_local}")
        
        # V√©rifier qu'au moins un mod√®le est charg√©
        if model_gear is None and model_haki is None:
            print("‚ö†Ô∏è Aucun mod√®le charg√© - utilisation d'un mod√®le par d√©faut")
            model_gear = YOLO('yolov8n.pt')
            print("‚ö†Ô∏è Mod√®le par d√©faut charg√© (yolov8n)")
            
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
        model_gear = None
        model_haki = None

def pieces_to_fen(detections, image_width, image_height):
    """
    Convertit les d√©tections de pi√®ces en notation FEN
    
    Args:
        detections: Liste des d√©tections avec position et classe
        image_width: Largeur de l'image
        image_height: Hauteur de l'image
    
    Returns:
        str: Notation FEN de la position
    """
    # Cr√©er une grille 8x8 vide
    board = [['' for _ in range(8)] for _ in range(8)]
    
    # Mapping des noms de pi√®ces vers notation FEN
    piece_mapping = {
        'white-king': 'K', 'white-queen': 'Q', 'white-rook': 'R',
        'white-bishop': 'B', 'white-knight': 'N', 'white-pawn': 'P',
        'black-king': 'k', 'black-queen': 'q', 'black-rook': 'r',
        'black-bishop': 'b', 'black-knight': 'n', 'black-pawn': 'p',
        # Variantes possibles
        'king': 'K', 'queen': 'Q', 'rook': 'R',
        'bishop': 'B', 'knight': 'N', 'pawn': 'P',
        'black king': 'k', 'black queen': 'q', 'black rook': 'r',
        'black bishop': 'b', 'black knight': 'n', 'black pawn': 'p',
    }
    
    # Calculer la taille d'une case
    cell_width = image_width / 8
    cell_height = image_height / 8
    
    # Placer chaque pi√®ce d√©tect√©e sur la grille
    for det in detections:
        piece_name = det['class'].lower()
        
        # Obtenir le symbole FEN
        fen_symbol = piece_mapping.get(piece_name, '')
        if not fen_symbol:
            continue
        
        # Calculer la position centrale de la pi√®ce
        center_x = (det['bbox']['x1'] + det['bbox']['x2']) / 2
        center_y = (det['bbox']['y1'] + det['bbox']['y2']) / 2
        
        # Convertir en coordonn√©es d'√©chiquier (0-7)
        col = int(center_x / cell_width)
        row = int(center_y / cell_height)
        
        # S'assurer que les coordonn√©es sont valides
        col = max(0, min(7, col))
        row = max(0, min(7, row))
        
        # Placer la pi√®ce (noter que row 0 = haut de l'image = rang 8 aux √©checs)
        board[row][col] = fen_symbol
    
    # Construire la cha√Æne FEN
    fen_rows = []
    for row in board:
        fen_row = ''
        empty_count = 0
        
        for cell in row:
            if cell == '':
                empty_count += 1
            else:
                if empty_count > 0:
                    fen_row += str(empty_count)
                    empty_count = 0
                fen_row += cell
        
        if empty_count > 0:
            fen_row += str(empty_count)
        
        fen_rows.append(fen_row)
    
    # Joindre avec '/' et ajouter les m√©tadonn√©es FEN par d√©faut
    fen = '/'.join(fen_rows)
    fen += ' w KQkq - 0 1'  # M√©tadonn√©es: blancs jouent, tous les roques possibles, etc.
    
    return fen

@app.route('/', methods=['GET'])
def home():
    """Page d'accueil de l'API"""
    return jsonify({
        'name': 'Senchess AI API',
        'version': '1.0.0',
        'description': 'API de d√©tection de pi√®ces d\'√©checs avec YOLO',
        'endpoints': {
            '/': 'Cette page',
            '/health': 'V√©rifier l\'√©tat de l\'API',
            '/predict': 'POST - Analyser une image d\'√©chiquier'
        }
    })

@app.route('/health', methods=['GET'])
def health():
    """V√©rifier l'√©tat de l'API et du mod√®le"""
    models_loaded = {
        'gear': model_gear is not None,
        'haki': model_haki is not None
    }
    
    any_loaded = model_gear is not None or model_haki is not None
    
    return jsonify({
        'status': 'healthy' if any_loaded else 'model_not_loaded',
        'model_type': MODEL_TYPE,
        'models_loaded': models_loaded,
        'use_huggingface': USE_HUGGINGFACE,
        'repo_id': HUGGINGFACE_REPO if USE_HUGGINGFACE else 'local'
    })

@app.route('/predict', methods=['POST'])
def predict():
    """
    Endpoint principal pour la d√©tection de pi√®ces d'√©checs
    
    Accepte:
    - image: fichier image (multipart/form-data)
    - image_url: URL d'une image
    - image_base64: image encod√©e en base64
    - conf: seuil de confiance (optionnel, d√©faut 0.25)
    - model: 'gear', 'haki' ou 'ensemble' (optionnel, utilise MODEL_TYPE par d√©faut)
    
    Retourne:
    - fen: notation FEN de la position
    - pieces: liste des pi√®ces d√©tect√©es
    - confidence: confiance moyenne
    - detectedPieces: nombre de pi√®ces d√©tect√©es
    """
    # V√©rifier qu'au moins un mod√®le est charg√©
    if model_gear is None and model_haki is None:
        return jsonify({
            'error': 'Mod√®le non charg√©',
            'message': 'Aucun mod√®le YOLO n\'a pu √™tre charg√©'
        }), 500
    
    try:
        # Param√®tres
        conf_threshold = float(request.form.get('conf', 0.25))
        requested_model = request.form.get('model', MODEL_TYPE)
        
        # R√©cup√©rer l'image depuis diff√©rentes sources
        image = None
        
        # 1. Fichier upload√©
        if 'image' in request.files:
            file = request.files['image']
            image_bytes = file.read()
            image = Image.open(io.BytesIO(image_bytes))
        
        # 2. Image base64
        elif 'image_base64' in request.form:
            image_base64 = request.form['image_base64']
            # Enlever le pr√©fixe data:image/...;base64, si pr√©sent
            if ',' in image_base64:
                image_base64 = image_base64.split(',')[1]
            image_bytes = base64.b64decode(image_base64)
            image = Image.open(io.BytesIO(image_bytes))
        
        # 3. URL d'image (√† impl√©menter si n√©cessaire)
        elif 'image_url' in request.form:
            return jsonify({
                'error': 'Non impl√©ment√©',
                'message': 'Le t√©l√©chargement depuis URL n\'est pas encore support√©'
            }), 501
        
        else:
            return jsonify({
                'error': 'Aucune image fournie',
                'message': 'Veuillez fournir une image via "image", "image_base64" ou "image_url"'
            }), 400
        
        # Convertir PIL Image en format compatible OpenCV
        image_np = np.array(image)
        if len(image_np.shape) == 2:  # Grayscale
            image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)
        elif image_np.shape[2] == 4:  # RGBA
            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)
        
        image_height, image_width = image_np.shape[:2]
        
        # Sauvegarder temporairement l'image
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_path = tmp_file.name
            cv2.imwrite(tmp_path, cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))
        
        # Choisir le mod√®le √† utiliser
        detections = []
        
        if requested_model == 'ensemble' and model_gear and model_haki:
            # Mode ensemble : utiliser les deux mod√®les
            detections = predict_ensemble(tmp_path, conf_threshold)
        elif requested_model == 'haki' and model_haki:
            # Utiliser Haki
            detections = predict_with_model(model_haki, tmp_path, conf_threshold)
        elif model_gear:
            # Utiliser Gear (par d√©faut)
            detections = predict_with_model(model_gear, tmp_path, conf_threshold)
        elif model_haki:
            # Fallback sur Haki si Gear n'est pas disponible
            detections = predict_with_model(model_haki, tmp_path, conf_threshold)
        
        # Nettoyer le fichier temporaire
        os.unlink(tmp_path)
        
        # Calculer la confiance moyenne
        confidences = [d['confidence'] for d in detections]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        # Convertir en FEN
        fen = pieces_to_fen(detections, image_width, image_height)
        
        # Pr√©parer la r√©ponse
        response = {
            'success': True,
            'fen': fen,
            'pieces': detections,
            'confidence': round(avg_confidence, 3),
            'detectedPieces': len(detections),
            'description': f'Position d√©tect√©e avec {len(detections)} pi√®ces',
            'model_used': requested_model,
            'imageSize': {
                'width': image_width,
                'height': image_height
            },
            'warnings': []
        }
        
        # Ajouter des avertissements si n√©cessaire
        if avg_confidence < 0.8:
            response['warnings'].append('Confiance faible - v√©rifiez la qualit√© de l\'image')
        
        if len(detections) < 2:
            response['warnings'].append('Peu de pi√®ces d√©tect√©es - v√©rifiez que l\'√©chiquier est visible')
        
        return jsonify(response)
    
    except Exception as e:
        return jsonify({
            'error': 'Erreur lors de la pr√©diction',
            'message': str(e)
        }), 500

def predict_with_model(model, image_path, conf_threshold):
    """Effectue une pr√©diction avec un mod√®le unique"""
    results = model.predict(
        source=image_path,
        conf=conf_threshold,
        save=False,
        verbose=False
    )
    
    detections = []
    for result in results:
        boxes = result.boxes
        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            class_id = int(box.cls[0])
            confidence = float(box.conf[0])
            class_name = result.names[class_id]
            
            detections.append({
                'id': len(detections) + 1,
                'class': class_name,
                'confidence': round(confidence, 3),
                'bbox': {
                    'x1': round(x1, 2),
                    'y1': round(y1, 2),
                    'x2': round(x2, 2),
                    'y2': round(y2, 2),
                    'width': round(x2 - x1, 2),
                    'height': round(y2 - y1, 2)
                }
            })
    
    return detections

def predict_ensemble(image_path, conf_threshold):
    """
    Pr√©diction ensemble combinant Gear et Haki
    - Gear pour toutes les pi√®ces
    - Haki pour les pi√®ces strat√©giques (King, Queen, Rook, Bishop) avec priorit√©
    """
    strategic_pieces = [
        'king', 'queen', 'rook', 'bishop',
        'black-king', 'black-queen', 'black-rook', 'black-bishop',
        'white-king', 'white-queen', 'white-rook', 'white-bishop'
    ]
    
    # 1. Pr√©dictions Gear (toutes les pi√®ces)
    gear_detections = predict_with_model(model_gear, image_path, conf_threshold)
    
    # 2. Pr√©dictions Haki (pi√®ces strat√©giques)
    haki_detections = predict_with_model(model_haki, image_path, conf_threshold)
    
    # 3. Combiner intelligemment
    final_detections = []
    used_positions = []
    
    def boxes_overlap(box1, box2, threshold=0.5):
        """V√©rifie si deux bo√Ætes se chevauchent"""
        x1_min, y1_min = box1['x1'], box1['y1']
        x1_max, y1_max = box1['x2'], box1['y2']
        x2_min, y2_min = box2['x1'], box2['y1']
        x2_max, y2_max = box2['x2'], box2['y2']
        
        # Calculer l'intersection
        x_overlap = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))
        y_overlap = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))
        intersection = x_overlap * y_overlap
        
        # Calculer les aires
        area1 = (x1_max - x1_min) * (y1_max - y1_min)
        area2 = (x2_max - x2_min) * (y2_max - y2_min)
        union = area1 + area2 - intersection
        
        return intersection / union > threshold if union > 0 else False
    
    # Prioriser les d√©tections Haki pour les pi√®ces strat√©giques
    for haki_det in haki_detections:
        if haki_det['class'].lower() in strategic_pieces:
            final_detections.append(haki_det)
            used_positions.append(haki_det['bbox'])
    
    # Ajouter les d√©tections Gear non chevauchantes
    for gear_det in gear_detections:
        overlaps = False
        for used_pos in used_positions:
            if boxes_overlap(gear_det['bbox'], used_pos):
                overlaps = True
                break
        
        if not overlaps:
            final_detections.append(gear_det)
    
    # R√©assigner les IDs
    for i, det in enumerate(final_detections):
        det['id'] = i + 1
    
    return final_detections

# Charger le mod√®le au d√©marrage
load_model()

# Pour Vercel, exporter l'app
# Vercel utilisera cette variable pour g√©rer les requ√™tes
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
